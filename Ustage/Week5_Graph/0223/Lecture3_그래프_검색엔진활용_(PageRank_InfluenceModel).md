#### 1. 페이지랭크의 배경

1.1 웹과 그래프

- 웹은 웹페이지와 하이퍼링크로 구성된 거대한 방향성 있는 그래프입니다
- 웹페이지는 정점에 해당합니다
- 웹페이지가 포함하는 하이퍼링크는 해당 웹페이지에서 나가는 간선에 해당합니다
- 단, 웹페이지는 추가적으로 키워드 정보를 포함하고 있습니다

1.2 구글 이전의 검색 엔진

- 첫번째 시도는 웹을 거대한 디렉토리로 정리하는 것이었습니다
  - 웹페이지의 수가 증가함에 따라서 카테고리의 수와 깊이도 무한정 커지는 문제가 있습니다
  - 참고로 현재는 수십억 ~ 수백억 개의 웹페이지가 있는 것으로 알려져 있습니다
  - 또한, 카테고리 구분이 모호한 경우가 많아, 저장과 검색에 어려움이 있습니다
- 두번째 시도는 웹페이지에 포함된 키워드에 의존한 검색 엔진입니다
  - 사용자가 입력한 키워드에 대해, 해당 키워드를 (여러 번) 포함한 웹페이지를 반환합니다
  - 하지만, 이 방법은 악의적인 웹페이지에 취약하다는 단점이 있습니다
  - 예를 들어, 성인 사이트에 ‘축구’라는 키워드를 (보이지 않도록) 여러 번 포함하게 되면, ‘축구’를 검색했을 때 해당 성인 사이트가 결과로 나올 수 있습니다
- Q. 사용자 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 어떻게 찾을 수 있을까요?
  - A. 구글의 창업자인 래리 페이지(Larry Page)와 세르게이 브린(Sergey Brin)은 The PageRank Citation Ranking: Bringing Order to the Web 라는 제목의 논문을 통해 이 질문에 답합니다

#### 2. 페이지랭크의 정의



2.1 페이지랭크의 정의: 투표 관점

- 페이지랭크의 핵심 아이디어는 투표입니다

- 즉, 투표를 통해 사용자 키워드와 관련성이 높고 신뢰할 수 있는 웹페이지를 찾습니다

- 투표의 주체는 바로 웹페이지입니다

- 웹페이지는 하이퍼링크를 통해 투표를 합니다

- 사용자 키워드를 포함한 웹페이지들을 고려합시다

- 웹페이지 𝑢가 𝑣로의 하이퍼링크를 포함한다면?

- 𝑢의 작성자가 판단하기에 𝑣가 관련성이 높고 신뢰할 수 있다는 것을 의미합니다

- 즉, 𝑢가 𝑣에게 투표했다고 할 수 생각할 수 있습니다

- 즉, 들어오는 간선이 많을 수록 신뢰할 수 있다는 뜻입니다

- Q. 그런데 들어오는 간선의 수를 세는 것만으로 충분할까요?

  - A. 아닙니다. 악용될 소지가 있습니다
  - 웹페이지를 여러 개 만들어서 간선의 수를 부풀릴 수 있습니다
  - 즉, 관련성과 신뢰도가 높아 보이도록 조작할 수 있습니다

- Q. 이런 악용을 막으려면 어떻게 해야 할까요?

  - A. 이런 악용에 의한 효과를 줄이기 위해, 페이지랭크에서는 가중 투표를 합니다
  - 즉, 관련성이 높고 신뢰할 수 있는 웹사이트의 투표를 더 중요하게 간주합니다
  - 반면, 그렇지 않은 웹사이트들의 투표는 덜 중요하게 간주합니다
  - 악용이 없는 경우에도 사용할 수 있는 합리적인 투표 방법입니다

- Q. 잠깐, 관련성과 신뢰성은 저희가 투표를 통해 측정하려는 것 아니었나요?

  출력을 입력으로 사용하자는 이야기처럼 들리는데요?

  - A. 그렇습니다. 재귀(Recursion), 즉 연립방정식 풀이를 통해 가능합니다.

- 측정하려는 웹페이지의 관련성 및 신뢰도를 페이지랭크 점수라고 부릅시다

  - 각 웹페이지는 각각의 나가는 이웃에게 자신의 페이지랭크 점수/나가는 이웃의 수 만큼의 가중치로 투표를 합니다
  - 페이지랭크 점수의 정의는 다음과 같습니다
    ![img](https://media.vlpt.us/images/skaurl/post/fa550f20-7904-46c8-bdd5-b9349c82ac82/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-23%2009.43.23.png)

2.2 페이지랭크의 정의: 임의 보행 관점

- 페이지랭크는 임의 보행(Random Walk)의 관점에서도 정의할 수 있습니다
  - 임의 보행을 통해 웹을 서핑하는 웹서퍼를 가정합시다
  - 즉, 웹서퍼는 현재 웹페이지에 있는 하이퍼링크 중 하나를 균일한 확률로 클릭하는 방식으로 웹을 서핑합니다
  - 웹서퍼가 𝑡번째 방문한 웹페이지가 웹페이지 𝑖일 확률을 𝒑𝒊(𝒕)라고 합시다
  - 그러면 𝒑(𝒕)는 길이가 웹페이지 수와 같은 확률분포 벡터가 됩니다
  - 그러면 아래 식이 성립합니다
    ![img](https://media.vlpt.us/images/skaurl/post/171d3529-157c-4766-bf39-e624e415a549/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-23%2009.46.34.png)





---

막다른 정점에서 사라진 페이지 랭크 점수들의 합을 나눠주는 게 S랑 무슨 상관이 있는걸까?

>막다른 골목이 없는 그래프에서는 몇 번이고 반복곱을 하더라도 페이지 랭크의 총 합은 1로 유지됩니다. 막다른 골목이 있어서 어디선가 손실이 발생한다면, 페이지 랭크의 총 합을 S라 할 때 1-S를 통해 "사라진 페이지 랭크의 총 합"을 구할 수 있습니다. 이 값을 모든 정점에 동일하게 나눠주는 방식으로 전체 페이지랭크의 소실을 막을 수 있습니다. 그래서 마지막에 (1-S)/|V|를 모든 정점에 더해줍니다.









#### 3. 페이지랭크의 계산

3.1 페이지랭크의 계산: 반복곱

- 이지랭크 점수의 계산에는 반복곱(Power Iteration)을 사용합니다
- 반복곱은 다음 세 단계로 구성됩니다
  - (1) 각 웹페이지 𝑖의 페이지랭크 점수 𝒓𝒊(𝟎)를 동일하게 1/웹페이지의 수로 초기화합니다
  - (2) 아래 식을 이용하여 각 웹페이지의 페이지랭크 점수를 갱신합니다
    ![img](https://media.vlpt.us/images/skaurl/post/56bf54a4-49b9-4d46-b919-73029dfad436/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-23%2009.49.21.png)
  - (3) 페이지랭크 점수가 수렴하였으면 종료합니다. 아닌 경우 (2)로 돌아갑니다

3.2 문제점과 해결책

- 앞선 예시에서는 반복곱이 잘 동작하는 것을 알겠습니다 그런데...
- Q1. 반복곱이 항상 수렴하는 것을 보장할 수 있나요?
  - 정답은 ‘아니오’ 입니다
  - 들어오는 간선은 있지만 나가는 간선은 없는 정점 집합인 스파이더 트랩(Spider Trap)에 의한 문제입니다
- Q2. 반복곱이 “합리적인” 점수로 수렴하는 것을 보장할 수 있나요?
  - 정답은 ‘아니오’ 입니다
  - 들어오는 간선은 있지만 나가는 간선은 없는 막다른 정점(Dead End)에 의한 문제입니다
- 문제 해결을 위해 순간이동(Teleport)을 도입합니다
- 임의 보행 관점에서, 웹을 서핑하는 웹서퍼의 행동을 다음과 같이 수정합니다
  - (1) 현재 웹페이지에 하이퍼링크가 없다면, 임의의 웹페이지로 순간이동 합니다
  - (2) 현재 웹페이지에 하이퍼링크가 있다면, 앞면이 나올 확률이 𝛼인 동전을 던집니다
  - (3) 앞면이라면, 하이퍼링크 중 하나를 균일한 확률로 선택해 클릭합니다
  - (4) 뒷면이라면, 임의의 웹페이지로 순간이동 합니다
- (1)과 (4)의 임의의 웹페이지는 전체 웹페이지들 중에 하나를 균일확률로 선택합니다
- 순간이동에 의해서 스파이더 트랩이나 막다른 정점에 갇히는 일이 없어졌습니다
- 𝛼를 감폭 비율(Damping Factor)이라고 부르며 값으로 보통 0.8 정도를 사용합니다
- 순간이동 도입은 페이지랭크 점수 계산을 다음과 같이 바꿉니다
  - (1) 각 막다른 정점에서 (자신을 포함) 모든 다른 정점으로 가는 간선을 추가합니다
  - (2) 아래 수식을 사용하여 반복곱을 수행합니다
    ![img](https://media.vlpt.us/images/skaurl/post/76a3e95e-2370-440a-93a5-8fe6e7a4408e/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-23%2009.53.59.png)
  - |𝑉|는 전체 웹페이지의 수를 의미합니다
  - 파란색 부분은 하이퍼링크를 따라 정점 𝑗에 도착할 확률을 의미합니다
  - 빨간색 부분은 순간이동을 통해 정점 𝑗에 도착할 확률을 의미합니다





> 3강 정리

- 페이지랭크의 배경
  - 디렉토리, 키워드 기반 검색 엔진의 한계
- 페이지랭크의 정의
  - 투표 관점 : 하이퍼링크를 통한 가중 투표
  - 임의 보행 관점 : 웹서퍼가 각 웹페이지를 방문할 확률
- 페이지랭크의 계산
  - 반복곱
  - 스파이더 트랩 및 막다른 정점 문제를 해결하기 위한 순간 이동









