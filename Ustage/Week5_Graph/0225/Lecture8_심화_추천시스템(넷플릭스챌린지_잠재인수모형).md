#### 1. 추천시스템 기본 복습

1.1 추천 시스템 예시

- Amazon.com (상품), 넷플릭스 (영화), 유튜브 (영상), 페이스북 (친구)

1.2 추천 시스템과 그래프

- 추천 시스템은 사용자 각각이 구매할 만한 혹은 선호할 만한 상품/영화/영상을 추천합니다
- 추천 시스템의 핵심은 사용자별 구매를 예측하거나 선호를 추정하는 것입니다
- 그래프 관점에서 추천 시스템은 “미래의 간선을 예측하는 문제” 혹은 “누락된 간선의 가중치를 추정하는 문제”로 해석할 수 있습니다

1.3 내용 기반 추천시스템

- 내용 기반 추천은 각 사용자가 구매/만족했던 상품과 유사한 것을 추천하는 방법입니다
- 내용 기반 추천시스템은 다음 장/단점을 같습니다
  - 장점
    - (+) 다른 사용자의 구매 기록이 필요하지 않습니다
    - (+) 독특한 취향의 사용자에게도 추천이 가능합니다
    - (+) 새 상품에 대해서도 추천이 가능합니다
    - (+) 추천의 이유를 제공할 수 있습니다
  - 단점
    - (-) 상품에 대한 부가 정보가 없는 경우에는 사용할 수 없습니다
    - (-) 구매 기록이 없는 사용자에게는 사용할 수 없습니다
    - (-) 과적합(Overfitting)으로 지나치게 협소한 추천을 할 위험이 있습니다

1.4 협업 필터링

- 협업 필터링은 유사한 취향의 사용자들이 선호/구매한 상품을 추천하는 방법입니다
- 협업 필터링은 다음의 장/단점을 갖습니다
  - 장점
    - (+) 상품에 대한 부가 정보가 없는 경우에도 사용할 수 있습니다
  - 단점
    - (−) 충분한 수의 평점 데이터가 누적되어야 효과적입니다
    - (−) 새 상품, 새로운 사용자에 대한 추천이 불가능합니다
    - (−) 독특한 취향의 사용자에게 추천이 어렵습니다

1.5 추천시스템의 평가

- 훈련 데이터를 이용하여 추정한 점수를 평가 데이터와 비교하여 정확도를 측정합니다
- 오차를 측정하는 지표로는 평균 제곱 오차(Mean Squared Error, MSE)가 많이 사용됩니다 평가 데이터 내의 평점들을 집합을 𝑇라고 합시다
- 평균 제곱급 오차(Root Mean Squared Error, RMSE)도 많이 사용됩니다

#### 2. 넷플릭스 챌린지 소개

2.1 넷플릭스 챌린지 데이터셋

- 넷플릭스 챌린지(Netflix Challenge)에서는 사용자별 영화 평점 데이터가 사용되었습니다
- 훈련 데이터(Training Data)는 2000년부터 2005년까지 수집한
- 48만명 사용자의 1만 8천개의 영화에 대한 1억 개의 평점으로 구성되어 있습니다
- 평가 데이터(Test Data)는 각 사용자의 최신 평점 280만개로 구성되어 있습니다

2.2 넷플릭스 챌린지 대회 소개

- 넷플릭스 챌린지의 목표는 추천시스템의 성능을 10%이상 향상시키는 것이었습니다
- 평균 제곱근 오차 0.9514을 0.8563까지 낮출 경우 100만불의 상금을 받는 조건이었습니다
- 2006년부터 2009년까지 진행되었으며, 2700개의 팀이 참여하였습니다
- 넷플릭스 챌린지를 통해 추천시스템의 성능이 비약적으로 발전했습니다

#### 3. 잠재 인수 모형

3.1 잠재 인수 모형 개요

- 잠재 인수 모형(Latent Factor Model)의 핵심은 사용자와 상품을 벡터로 표현하는 것입니다
- 잠재 인수 모형에서는 고정된 인수 대신 효과적인 인수를 학습하는 것을 목표로 합니다
- 학습한 인수를 잠재 인수(Latent Factor)라 부릅니다

3.2 손실 함수

- 사용자와 상품을 임베딩하는 기준은 무엇인가요?
- 사용자와 상품의 임베딩의 내적(Inner Product)이 평점과 최대한 유사하도록 하는 것입니다
- 사용자 𝑥의 임베딩을 𝑝𝑥, 상품 𝑖의 임베딩을 𝑞𝑖라고 합시다
- 사용자 𝑥의 상품 𝑖에 대한 평점을 𝑟𝑥𝑖라고 합시다
- 임베딩의 목표는 𝑝𝑥⊺𝑞𝑖이 𝑟𝑥𝑖와 유사하도록 하는 것입니다
- 사용자 수의 열과 상품 수의 행을 가진 평점 행렬을 𝑅이라고 합시다
- 사용자들의 임베딩, 즉 벡터를 쌓아서 만든 사용자 행렬을 𝑃라고 합시다
- 영화들의 임베딩, 즉 벡터를 쌓아서 만든 상품 행렬을 𝑄라고 합시다
- 잠재 인수 모형은 다음 손실 함수를 최소화하는 𝑃와 𝑄를 찾는 것을 목표로 합니다
  ![img](https://media.vlpt.us/images/skaurl/post/c1bfd1ce-65d5-4ed9-b679-6bf98513672e/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-25%2010.20.12.png)
- 하지만, 위 손실 함수를 사용할 경우 과적합(Overfitting)이 발생할 수 있습니다
- 과적합이란 기계학습 모형이 훈련 데이터의 잡음(Noise)까지 학습하여, 평가 성능은 오히려 감소하는 현상을 의미합니다
- 과적합을 방지하기 위하여 정규화 항을 손실 함수에 더해줍니다
  ![img](https://media.vlpt.us/images/skaurl/post/1bf39c8b-d40d-48f9-9dcb-e7dfff4f78bc/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-25%2010.20.46.png)
- 정규화는 극단적인, 즉 절댓값이 너무 큰 임베딩을 방지하는 효과가 있습니다

3.3 최적화

- 손실함수를 최소화하는 𝑃와 𝑄를 찾기 위해서는 (확률적) 경사하강법을 사용합니다
  - 경사하강법은 손실함수를 안정적으로 하지만 느리게 감소시킵니다
  - 확률적 경사하강법은 손실함수를 불안정하지만 빠르게 감소시킵니다
  - 실제로는 확률적 경사하강법이 더 많이 사용됩니다

#### 4. 고급 잠재 인수 모형

4.1 사용자와 상품의 편향을 고려한 잠재 인수 모형

- 각 사용자의 편향은 해당 사용자의 평점 평균과 전체 평점 평균의 차입니다
- 개선된 잠재 인수 모형에서는 평점을 전체 평균, 사용자 편향, 상품 편향, 상호작용으로 분리합니다
  ![img](https://media.vlpt.us/images/skaurl/post/48f98845-6bbe-440b-ab92-a32c57efd1d4/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-25%2010.22.40.png)
- 개선된 잠재 인수 모형의 손실 함수는 아래와 같습니다
  ![img](https://media.vlpt.us/images/skaurl/post/c96e00ed-d1a3-4503-930f-3205b5b5252b/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-25%2010.23.25.png)
- (확률적) 경사하강법을 통해 손실 함수를 최소화하는 잠재 인수와 편향을 찾아냅니다

4.2 시간적 편향을 고려한 잠재 인수 모형

- 넷플릭스 시스템의 변화로 평균 평점이 크게 상승하는 사건이 있었습니다
- 영화의 평점은 출시일 이후 시간이 지남에 따라 상승하는 경향을 갖습니다
- 개선된 잠재 인수 모형에서는 이러한 시간적 편향을 고려합니다
- 구체적으로 사용자 편향과 상품 편향을 시간에 따른 함수로 가정합니다
  ![img](https://media.vlpt.us/images/skaurl/post/79645720-656f-425e-9f8c-31aebaf755cd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-02-25%2010.25.00.png)

#### 5. 넷플릭스 챌린지의 결과

5.1 앙상블 학습

- BellKor 팀은 앙상블 학습을 사용하여 처음으로 목표 성능에 도달하였습니다
- BellKor 팀의 독주에 위기감을 느낀 다른 팀들은 연합팀 Ensemble을 만들었습니다
- 그 결과 Ensemble 팀 역시 목표 성능에 도달하였습니다

5.2. 넷플릭스 챌린지의 우승팀

- 넷플릭스 챌린지 종료 시점에 BellKor 팀 Ensemble 팀의 오차는 정확히 동일했습니다
- 하지만 BellKor 팀의 제출이 20분 빨랐습니다.
- BellKor 팀의 우승입니다!

#### 8강 정리

1. 추천시스템 기본 복습
   - 내용 기반 추천, 협업 필터링 등
2. 넷플릭스 챌린지 소개

3. 기본 잠재 인수 모형

   - 사용자정보와 상품 정보를 임베딩하기 위한 학습
   - (임베딩할 차원은 선택해야함, GridSearch 등 CV활용)

   - 임베딩의 내적으로 평점을 근사

4. 고급 잠재 인수 모형

   - 사용자 편향과 상품 편향을 고려

   - 시간적 편향까지 고려

5. 넷플릭스 챌린지의 결과



※ 궁금한 점

위에서 본 바로, 잠재 인수모형은 지난 시간에 배웠던 정점 표현 학습 방법 중 한 가지에 속하는 것 같아 보인다.

그렇다면 모형을 적합시키는 과정이 있으므로, 변환식 정점 표현방법이 아니라 귀납적 정점 표현 방법에 속할 것 같다. (새로운 정보가 추가되어도 바로 정보를 임베딩할 수 있다.)





**Further Questions**

- 추천시스템의 성능을 측정하는 metric이 RMSE라는 것은 예상 평점이 높은 상품과 낮은 상품에 동일한 페널티를 부여한다는 것을 뜻합니다. 하지만 실제로 추천시스템에서는 내가 좋아할 것 같은 상품을 추천해주는것, 즉 예상 평점이 높은 상품을 잘 맞추는것이 중요합니다. 이를 고려하여 성능을 측정하기 위해서는 어떻게 해야 할까요?
  - 예상평점이 높을 것으로 예상되는 부분에 가중치를 더 높게 적용한 WRMSE를 사용하면 될 것 같다.


$$
y_i = actual \ value
\\
\hat y_i = predicted \ value
\\

\\
RMSE = \sum^n_{i=1}(y_i - \hat y_i)^2
\\
weighted \ RMSE = \sum^n_{i=1}\hat y_i(y_i - \hat y_i)^2
\\
\hat y_i는 0보다\ 크다고\ 가정
$$



> Answer) Recall@k, Precisoin@k, MAP, MRR, NDCG 등의 랭킹 기반 메트릭을 활용한다.
>
> 참고 : https://zzaebok.github.io/recommender_system/metrics/rec_metrics/






- 추천 시스템의 성능을 향상시키기 위해서는 어떠한 것을 더 고려할 수 있을까요? (해당 문제는 정답이 제공되지 않는 문제입니다. 자유롭게 여러분의 의견을 이야기해보세요.)

  - UV decomposition는 여러 가지의 local minima로 수렴시킬 수 있으니까 이 여러 가지의 decomposition을 구한 뒤 이들의 평균을 구한다면 과대적합을 막을 수가 있다.
