{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규진님이 주신 데이터셋 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://boostcamp.stages.ai/competitions/4/discussion/post/174\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"../input/data/train/train.tsv\",sep='\\t',header=None)\n",
    "test = pd.read_csv(\"../input/data/test/test.tsv\",sep='\\t',header=None)\n",
    "process_external_data = pd.read_csv(\"../input/data/process_external_data/all_csv.tsv\",sep='\\t',header=None)\n",
    "process_external_data.iloc[:,1] = process_external_data.iloc[:,1].apply(lambda x: x.strip())\n",
    "# origin_external_data = pd.read_csv(\"../input/data/external_data/train.tsv\",sep='\\t',header=None)\n",
    "\n",
    "process_vc = process_external_data.iloc[:,8].value_counts()\n",
    "train_vc = train.iloc[:,8].value_counts()\n",
    "from transformers import AutoTokenizer\n",
    "# model_name_from_pretrained = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model_name_from_pretrained = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_from_pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wikipedia-24896-25-30-33-19-21</td>\n      <td>영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...</td>\n      <td>랜드로버</td>\n      <td>30</td>\n      <td>33</td>\n      <td>자동차</td>\n      <td>19</td>\n      <td>21</td>\n      <td>단체:제작</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wikipedia-12728-224-5-7-42-44</td>\n      <td>선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...</td>\n      <td>민주당</td>\n      <td>5</td>\n      <td>7</td>\n      <td>27석</td>\n      <td>42</td>\n      <td>44</td>\n      <td>관계_없음</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>wikipedia-28460-3-0-7-9-12</td>\n      <td>유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...</td>\n      <td>유럽 축구 연맹</td>\n      <td>0</td>\n      <td>7</td>\n      <td>UEFA</td>\n      <td>9</td>\n      <td>12</td>\n      <td>단체:별칭</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                0  \\\n0  wikipedia-24896-25-30-33-19-21   \n1   wikipedia-12728-224-5-7-42-44   \n2      wikipedia-28460-3-0-7-9-12   \n\n                                                   1         2   3   4     5  \\\n0  영국에서 사용되는 스포츠 유틸리티 자동차의 브랜드로는 랜드로버(Land Rover)...      랜드로버  30  33   자동차   \n1  선거에서 민주당은 해산 전 의석인 230석에 한참 못 미치는 57석(지역구 27석,...       민주당   5   7   27석   \n2  유럽 축구 연맹(UEFA) 집행위원회는 2014년 1월 24일에 열린 회의를 통해 ...  유럽 축구 연맹   0   7  UEFA   \n\n    6   7      8  \n0  19  21  단체:제작  \n1  42  44  관계_없음  \n2   9  12  단체:별칭  "
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (675 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train['token_len'] = train.iloc[:,1].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "test['token_len'] = test.iloc[:,1].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "process_external_data['token_len'] = process_external_data.iloc[:,1].apply(lambda x: len(tokenizer(x)['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3와 Q1 이용 문장길이 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_token_Q1 = train['token_len'].quantile(.25)\n",
    "# train_token_Q3 = train['token_len'].quantile(.75)\n",
    "# train_IQR = train_token_Q3-train_token_Q1\n",
    "# test_token_Q1 = test['token_len'].quantile(.25)\n",
    "# test_token_Q3 = test['token_len'].quantile(.75)\n",
    "# test_IQR = test_token_Q3-test_token_Q1\n",
    "# print(train_token_Q1,train_token_Q3,train_IQR)\n",
    "# print(test_token_Q1,test_token_Q3,test_IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train의 Q3 와 Q1 이용\n",
    "# print(process_external_data.shape)\n",
    "# condition = (train_token_Q1<process_external_data['token_len'])&(process_external_data['token_len']<train_token_Q3)\n",
    "# external_data_filtered_q3_q1 = process_external_data.loc[condition,:]\n",
    "# print(external_data_filtered_q3_q1.shape)\n",
    "# external_data_filtered_q3_q1.iloc[:,8].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최대 최소값 이용한 문장길이 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 341\n",
      "13 224\n",
      "5 5615\n",
      "(229611, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(225578, 10)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train['token_len'].min(),train['token_len'].max())\n",
    "print(test['token_len'].min(),test['token_len'].max())\n",
    "print(process_external_data['token_len'].min(),process_external_data['token_len'].max())\n",
    "print(process_external_data.shape)\n",
    "# condition = (test['token_len'].min()<process_external_data['token_len'])&(process_external_data['token_len']<test['token_len'].max())\n",
    "condition = (train['token_len'].min()<process_external_data['token_len'])&(process_external_data['token_len']<train['token_len'].max())\n",
    "process_external_data.loc[condition,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "인물:출신성분/국적    77850\n인물:직업/직함      34615\n단체:창립일        27757\n인물:제작         16601\n단체:제작         15039\n단체:구성원        13779\n인물:배우자        11205\n인물:자녀         10461\n인물:기타_친족       9650\n인물:부모님         4566\n단체:상위_단체       3436\n인물:학교          2062\n단체:정치/종교성향     1591\n인물:소속단체         875\n단체:창립자          124\nName: 8, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_external_data.iloc[:,8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_max_min_dict = {}\n",
    "for label_name in train_vc.index:\n",
    "  # label_name = '인물:학교'\n",
    "  token_len_for_label = process_external_data[process_external_data[8]==label_name]['token_len']\n",
    "  external_max_min_dict[label_name]=[token_len_for_label.max(),token_len_for_label.min()]\n",
    "\n",
    "train_max_min_dict = {}\n",
    "for label_name in train_vc.index:\n",
    "  # label_name = '인물:학교'\n",
    "  token_len_for_label = train[train[8]==label_name]['token_len']\n",
    "  train_max_min_dict[label_name]=[token_len_for_label.max(),token_len_for_label.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'관계_없음': [nan, nan],\n '단체:구성원': [279, 5],\n '인물:소속단체': [91, 13],\n '인물:직업/직함': [247, 5],\n '단체:상위_단체': [129, 12],\n '단체:별칭': [nan, nan],\n '인물:출신성분/국적': [317, 4],\n '인물:동료': [nan, nan],\n '단체:제작': [269, 5],\n '인물:부모님': [258, 7],\n '단체:본사_도시': [nan, nan],\n '단체:본사_국가': [nan, nan],\n '인물:별칭': [nan, nan],\n '인물:배우자': [523, 6],\n '인물:자녀': [317, 5],\n '단체:하위_단체': [nan, nan],\n '단체:창립일': [252, 5],\n '인물:기타_친족': [317, 5],\n '인물:제작': [4768, 5],\n '인물:형제/자매/남매': [nan, nan],\n '단체:창립자': [78, 14],\n '인물:사망_일시': [nan, nan],\n '단체:모회사': [nan, nan],\n '인물:출생_일시': [nan, nan],\n '인물:거주_국가': [nan, nan],\n '인물:거주_도시': [nan, nan],\n '단체:본사_주(도)': [nan, nan],\n '단체:정치/종교성향': [218, 6],\n '단체:해산일': [nan, nan],\n '인물:종교': [nan, nan],\n '인물:거주_주(도)': [nan, nan],\n '인물:용의자': [nan, nan],\n '단체:주주': [nan, nan],\n '단체:구성원_수': [nan, nan],\n '인물:학교': [215, 7],\n '인물:출생_국가': [nan, nan],\n '인물:사망_원인': [nan, nan],\n '인물:나이': [nan, nan],\n '단체:자회사': [nan, nan],\n '인물:출생_도시': [nan, nan],\n '인물:사망_도시': [nan, nan],\n '인물:사망_국가': [nan, nan]}"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max_min_dict\n",
    "external_max_min_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://rfriend.tistory.com/411"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수지님이 주신 데이터셋 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15402, 4)\n",
      "0\n",
      "325\n"
     ]
    }
   ],
   "source": [
    "# http://boostcamp.stages.ai/competitions/4/discussion/post/174\n",
    "import pandas as pd\n",
    "# train = pd.read_csv(\"../input/data/train/train.tsv\",sep='\\t',header=None)\n",
    "# test = pd.read_csv(\"../input/data/test/test.tsv\",sep='\\t',header=None)\n",
    "bornin_city = pd.read_csv(\"../input/data/process_external_data/19_bornin_city.tsv\",sep='\\t',header=0)\n",
    "bornin_country = pd.read_csv(\"../input/data/process_external_data/26_bornin_country.tsv\",sep='\\t',header=0)\n",
    "diedin_city = pd.read_csv(\"../input/data/process_external_data/37_diedin_city.tsv\",sep='\\t',header=0)\n",
    "diedin_country = pd.read_csv(\"../input/data/process_external_data/40_diedin_country.tsv\",sep='\\t',header=0)\n",
    "\n",
    "label_type = pd.read_pickle(\"../input/data/label_type.pkl\")\n",
    "reverse_label_dict = {v:k for k,v in label_type.items()}\n",
    "\n",
    "# minor_concat_data = pd.concat([bornin_city,bornin_country,diedin_city,diedin_country],axis=0)\n",
    "# print(minor_concat_data.shape)\n",
    "# minor_concat_data['label'] = minor_concat_data['label'].apply(lambda x: reverse_label_dict[x])\n",
    "# minor_concat_data.loc[:,'sentence'] = minor_concat_data.loc[:,'sentence'].apply(lambda x: x.strip())\n",
    "\n",
    "bornin_city['label'] = bornin_city['label'].apply(lambda x: reverse_label_dict[x])\n",
    "bornin_country['label'] = bornin_country['label'].apply(lambda x: reverse_label_dict[x])\n",
    "diedin_city['label'] = diedin_city['label'].apply(lambda x: reverse_label_dict[x])\n",
    "diedin_country['label'] = diedin_country['label'].apply(lambda x: reverse_label_dict[x])\n",
    "\n",
    "bornin_city.loc[:,'sentence'] = bornin_city.loc[:,'sentence'].apply(lambda x: x.strip())\n",
    "bornin_country.loc[:,'sentence'] = bornin_country.loc[:,'sentence'].apply(lambda x: x.strip())\n",
    "diedin_city.loc[:,'sentence'] = diedin_city.loc[:,'sentence'].apply(lambda x: x.strip())\n",
    "diedin_country.loc[:,'sentence'] = diedin_country.loc[:,'sentence'].apply(lambda x: x.strip())\n",
    "\n",
    "# def condition(x):\n",
    "#   return (\"'\" in x or \";\" in x or \":\" in x or '\"' in x or '@' in x or '#' in x or '$' in x or '^' in x or '&' in x or '+' in x or '/' in x or '*' in x or '*' in x or '*' in x)\n",
    "import re\n",
    "def check_punc(word):\n",
    "  reg = re.compile(r'[『』=+#/\\?:^$.@*\\\"※~&%·!\\\\|\\(\\)\\[\\]\\<\\>`\\'《》…]')\n",
    "  if reg.match(word):\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "mydata = bornin_city\n",
    "print(mydata.shape)\n",
    "# print(sum(mydata['sentence'].apply(lambda x: not condition(x))))\n",
    "\n",
    "\n",
    "\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: 1 if \"'\" in x else 0)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: 1 if \"`\" in x else 0)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: 1 if \";\" in x else 0)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: 1 if '\"' in x else 0)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: True if '※' in x else False)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: True if '·' in x else False)))\n",
    "# print(sum(bornin_city['sentence'].apply(lambda x: True if \"?\" in x else False)))\n",
    "\n",
    "# ['id','sentence','entity_01','ent1_start','ent1_end','entity_02','ent2_start','ent2_end','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'abcdef'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleanText(data):\n",
    "  text = re.sub('[『』=+#/\\?:^$.@*\\\"※~&%·!\\\\|\\(\\)\\{\\}\\[\\]\\<\\>`\\'《》…]','',data)\n",
    "  return text\n",
    "\n",
    "data = \"!?@#abcdef<>{}[]()\"\n",
    "cleanText(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_punc(data,pattern):\n",
    "  return sum(data[1].apply(lambda x: True if pattern in x else False))\n",
    "punc_list = [\"『\",\"』\",\"=\",\"+\",\"#\",\"/\",\"\\\\\",\"?\",\":\",\";\",\"^\",\"$\",\".\",\"@\",\"*\",\"\\\"\",\"※\",\"~\",\"&\",\"%\",\"·\",\"!\",\"|\",\"(\",\")\",\"{\",\"}\",\"[\",\"]\",\"<\",\">\",\"`\",\"\\'\",\"《\",\"》\",\"…\"]\n",
    "\n",
    "train_num_punc_dict = {punc:num_punc(train,punc) for punc in punc_list}\n",
    "test_num_punc_dict = {punc:num_punc(test,punc) for punc in punc_list}\n",
    "\n",
    "tr_no_punc=[punc for punc in punc_list if num_punc(train,punc)==0]\n",
    "tr_exist_punc=[punc for punc in punc_list if num_punc(train,punc)!=0]\n",
    "\n",
    "te_no_punc=[punc for punc in punc_list if num_punc(test,punc)==0]\n",
    "te_exist_punc=[punc for punc in punc_list if num_punc(test,punc)!=0]\n",
    "\n",
    "\n",
    "# 『』=+#/\\?:^$.@*\\\"※~&%·!\\\\|\\(\\)\\{\\}\\[\\]\\<\\>`\\'《》…\n",
    "\n",
    "# for punc in punc_list:\n",
    "#   print(f\"test 중 {punc}의 개수 {num_punc(test,punc)}\",end='\\n'+'='*20+'\\n')\n",
    "\n",
    "# num_punc(train,\"『\")\n",
    "# num_punc(train,\"』\")\n",
    "# num_punc(train,\"=\")\n",
    "# num_punc(train,\"+\")\n",
    "# num_punc(train,\"#\")\n",
    "# num_punc(train,\"/\")\n",
    "# num_punc(train,\"?\")\n",
    "# num_punc(train,\":\")\n",
    "# num_punc(train,\";\")\n",
    "# num_punc(train,\"^\")\n",
    "# num_punc(train,\"$\")\n",
    "# num_punc(train,\".\")\n",
    "# num_punc(train,\"@\")\n",
    "# num_punc(train,\"*\")\n",
    "# num_punc(train,'\\\"')\n",
    "# num_punc(train,\"※\")\n",
    "# num_punc(train,\"~\")\n",
    "# num_punc(train,\"&\")\n",
    "# num_punc(train,\"%\")\n",
    "# num_punc(train,\"·\")\n",
    "# num_punc(train,\"!\")\n",
    "# num_punc(train,\"\\\\\")\n",
    "# num_punc(train,\"|\")\n",
    "# num_punc(train,\"(\")\n",
    "# num_punc(train,\")\")\n",
    "# num_punc(train,\"{\")\n",
    "# num_punc(train,\"}\")\n",
    "# num_punc(train,\"[\")\n",
    "# num_punc(train,\"]\")\n",
    "# num_punc(train,\"<\")\n",
    "# num_punc(train,\">\")\n",
    "# num_punc(train,\"`\")\n",
    "# num_punc(train,\"\\'\")\n",
    "# num_punc(train,\"《\")\n",
    "# num_punc(train,\"》\")\n",
    "# num_punc(train,\"…\")\n",
    "\n",
    "# train과 test 모두 있는 특수기호들\n",
    "# / : ; . \"\n",
    "\n",
    "# train에는 있지만 test에는 없는 기호\n",
    "## 『 』 =  $ * `\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_num_punc_dict\n",
    "# test_num_punc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "관계_없음          4441\n단체:구성원          815\n인물:소속단체         679\n인물:직업/직함        553\n단체:상위_단체        335\n단체:별칭           231\n인물:출신성분/국적      209\n인물:동료           186\n단체:제작           165\n인물:부모님          164\n단체:본사_도시        136\n단체:본사_국가        115\n인물:별칭           103\n인물:배우자           92\n인물:자녀            84\n단체:하위_단체         80\n단체:창립일           67\n인물:기타_친족         58\n인물:제작            56\n인물:형제/자매/남매      52\n인물:사망_일시         45\n단체:창립자           45\n단체:모회사           44\n인물:출생_일시         36\n인물:거주_국가         27\n인물:거주_도시         26\n단체:본사_주(도)       23\n단체:정치/종교성향       18\n인물:종교            15\n단체:해산일           15\n인물:거주_주(도)       12\n인물:용의자           11\n단체:주주            11\n인물:학교             9\n단체:구성원_수          9\n인물:출생_국가          8\n인물:사망_원인          7\n단체:자회사            5\n인물:나이             5\n인물:출생_도시          4\n인물:사망_도시          3\n인물:사망_국가          1\nName: 8, dtype: int64"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "『 : 8개\n",
      "』 : 8개\n",
      "= : 2개\n",
      "+ : 0개\n",
      "# : 0개\n",
      "/ : 55개\n",
      "\\ : 0개\n",
      "? : 0개\n",
      ": : 105개\n",
      "; : 5개\n",
      "^ : 0개\n",
      "$ : 5개\n",
      ". : 9000개\n",
      "@ : 0개\n",
      "* : 4개\n",
      "\" : 655개\n",
      "※ : 0개\n",
      "~ : 368개\n",
      "& : 62개\n",
      "% : 206개\n",
      "· : 490개\n",
      "! : 28개\n",
      "| : 4개\n",
      "( : 2683개\n",
      ") : 2688개\n",
      "{ : 0개\n",
      "} : 0개\n",
      "[ : 21개\n",
      "] : 21개\n",
      "< : 0개\n",
      "> : 0개\n",
      "` : 7개\n",
      "' : 667개\n",
      "《 : 190개\n",
      "》 : 189개\n",
      "… : 0개\n"
     ]
    }
   ],
   "source": [
    "for k,v in train_num_punc_dict.items():\n",
    "  print(f\"{k} : {v}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train과 test 모두 없는 기호들 : ['>', '\\\\', '+', '※', '…', '^', '@', '{', '?', '}', '<', '#']\n",
      "train에만 있는 기호들 : ['*', '=', '『', '`', '$', '』']\n",
      "test에만 있는 기호들 : []\n",
      "train과 test 모두 있는 기호들 : ['|', '%', '》', '.', '\"', '·', '《', '!', '(', '/', ')', '[', ';', ']', \"'\", '&', ':', '~']\n",
      "외부데이터 추가시에 포함되어선 안될 특수기호들 : ['?', '>', '\\\\', '+', '*', '※', '^', '…', '=', '『', '}', '`', '@', '{', '$', '』', '<', '#']\n"
     ]
    }
   ],
   "source": [
    "print(f\"train과 test 모두 없는 기호들 : {list(set(tr_no_punc)&set(te_no_punc))}\")\n",
    "print(f\"train에만 있는 기호들 : {list(set(tr_exist_punc)-set(te_exist_punc))}\")\n",
    "print(f\"test에만 있는 기호들 : {list(set(te_exist_punc)-set(tr_exist_punc))}\")\n",
    "print(f\"train과 test 모두 있는 기호들 : {list(set(tr_exist_punc)&set(te_exist_punc))}\")\n",
    "\n",
    "print(f\"외부데이터 추가시에 포함되어선 안될 특수기호들 : {list(set(punc_list)-set(te_exist_punc))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entitiy1\n",
    "# train.iloc[:,2]\n",
    "\n",
    "# entity2\n",
    "# train.iloc[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train에 있는 특수기호들 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. * 은 (4개) \n",
    "replace('*','')로 단순 제거해주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_punc_dict['*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([\"지난 3일 아이즈원은 공식 SNS 채널에 첫 번째 정규앨범 '블룸아이즈(BLOOM*IZ)' 수록곡 메들리와 멤버별 모습을 공개했다.\",\n       '인천시(시장 박남춘)는 8월 19일(월)부터 8월 23일(금)까지 5일간 인천광역시 연수구 송도컨벤시아(프리미어볼룸)에서 개도국 고위급 인사, 국가지정기구(NDA*), 인증기구(AE**), 시민사회기관(CSO) 관계자 및 GCF 이사 등 800여명이 참석하는 녹색기후기금(GCF) 글로벌 프로그래밍 콘퍼런스가 개최한다고 밝혔다.',\n       '‘jp68****’은 아베 신조 일본 총리를 향해 “변태도 수출 규제 품목에 넣어라”라고 촉구했다.',\n       '2012년 10월 18일에는 B*Witched가 ITV2의 텔레비전 리얼리티 다큐멘터리 시리즈 《더 빅 리유니언》(The Big Reunion)에 출연하기 위하여 당대의 다른 5개의 팝 음악 그룹인 허니즈(Honeyz), 911, 리버티 X(Liberty X), 5ive, 아토믹 키튼(Atomic Kitten)와 함께 재결합할 것이라는 보도가 전해졌다.'],\n      dtype=object)"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에만 있는 기호들\n",
    "# * 는 replace('*','')로 제거하자.\n",
    "train[1].loc[train[1].apply(lambda x: True if '*' in x else False)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. = (데이터 2개)\n",
    "\n",
    "replace('本方=일본','일본')으로 대체\n",
    "\n",
    "replace('시마즈=아리마','시마즈-아리마')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num_punc_dict['=']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['내무성은 5개월 간의 조사 결과 이 문제는 이미 1699년에 끝난 문제로 울릉도와 이 섬은 조선 영토이며 ‘본방(本方=일본)과는 관계가 없다’고 결론짓고 일본 지도와 지적 조사에서 제외하기로 결정했다고 한국 학자들은 주장한다.',\n       '1584년 일어난 오키타나와테 전투에서 당시 류조지 가문의 당주 류조지 다카노부가 시마즈=아리마 연합군에 패사하였다.'],\n      dtype=object)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에만 있는 기호들\n",
    "# = 는 replace('本方=일본','일본')으로 대체\n",
    "# = 는 replace('시마즈=아리마','시마즈-아리마')\n",
    "train[1].loc[train[1].apply(lambda x: True if '=' in x else False)].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 『랑  』(쌍으로 8개)\n",
    "『 는 replace('『','《') 이중꺾쇠로 바꾸자\n",
    "\n",
    "』 는 replace('』','》') 이중꺾쇠로 바꾸자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "190\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(train_num_punc_dict['『'])\n",
    "print(train_num_punc_dict['《'])\n",
    "print(test_num_punc_dict['《'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['1992년부터 만화책을 원작으로 『짱구는 못말려』이라는 동명의 이름으로 신에이 동화에서 TV시리즈 애니메이션을 제작하여 테레비 아사히를 비롯한 아사히 방송(긴키 광역권), 나고야 TV(주쿄 광역권), 시즈오카 아사히 TV, 규슈 아사히 방송, 히로시마 홈 TV 등 24개 지역 민방 네트워크를 통해 방영되고 있다.',\n        '단체:제작'],\n       ['일본사회당을 서구의 사회민주주의와는 다른 사회민주주의로 받아들이고 그 차이를 긍정적으로 인식하는 분석은 시미즈 신조의 『일본의 사회민주주의』(이와나미 신서, 1961년)에서 비롯되었다.',\n        '단체:정치/종교성향'],\n       ['그 후 미쓰쿠니는 아버지 요리후사의 죽음으로 인해 가업을 상속하였고, 공무 수행으로 인해 바빠지는 바람에 편수 사업으로부터는 멀어지게 되었지만, 한편으로 막부에서는 간분 2년(1662년)에 하야시 가호(林鵞峰)에게 명해 편년체의 사서 『본조통감(本朝通鑑)』의 편찬을 개시하였고, 미쓰쿠니는 하야시 가보를 번저에 초대하여 면담하며, 편찬 방침이나 정통성 문제에 대해 질의하였다.',\n        '관계_없음'],\n       ['SK하이닉스가 협력사 대상 지식공유 플랫폼인 ‘반도체 아카데미’를 운영하며 축적된 반도체 전문지식과 경험을 공유하기 위하여 『패키지와 테스트(원제 : 반도체의 부가가치를 올리는 패키지와 테스트)』 책을 10일 펴냈다.',\n        '관계_없음'],\n       ['사단장은 북한군이 그대로 남진할 경우 서부전선이 위급하게 될 것임을 직감하고, 제7연대장 임부택 중령에게 『장호원을 즉각 탈취하라.』고 명령하였다.',\n        '인물:동료'],\n       ['일본사회당을 서구의 사회민주주의와는 다른 사회민주주의로 받아들이고 그 차이를 긍정적으로 인식하는 분석은 시미즈 신조의 『일본의 사회민주주의』(이와나미 신서, 1961년)에서 비롯되었다.',\n        '관계_없음'],\n       ['반면, 『매송론』(梅松論)에 묘사되어 있는, 다타라하마 전투(多々良浜の戦い) 당시에 전투에 임한 다카우지의 출정 모습이 본 초상와 흡사하고, 교토로 개선하는 다카우지가 이때의 모습을 화공에게 그리게 하였다는 기록도 남아 있어 역시 「기마무사상」이 아시카가 다카우지의 초상화가 맞지 않겠느냐는 의견도 있다.',\n        '관계_없음'],\n       ['이후에는 레이지의 멤버인 이노우에 슌지가 설립한 레코드 회사인 『란티스』(ランティス)로 이적(전속은 아님)했으며 2000년에 결성된 Jam Project의 리더로도 활동하고 있다.',\n        '단체:창립자']], dtype=object)"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에만 있는 기호들\n",
    "# 『 는 replace('『','[') 제거하자.\n",
    "# 』 는 replace('』','[') 제거하자.\n",
    "\n",
    "train.iloc[:,[1,8]].loc[train[1].apply(lambda x: True if '『' in x else False)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. $ (5개)\n",
    "\n",
    "R$ 는 replace('R$','금액') 으로 대체하자.\n",
    "\n",
    "AU$ 는 replace('AU$','금액') 으로 대체하자.\n",
    "\n",
    "$ 는 replace('$','금액') 으로 대체하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['이지연 신영증권 연구원은 “SK이노베이션의 올해 1분기 영업이익은 -1180억원으로 적자가 불가피할 전망”이라며 “코로나19의 영향으로 운송수요가 급감하였으며, 평년보다 따뜻한 날씨로 정제마진은 지난해 4분기 $2.1에서 올해 1분기 $0.5로 하락한 상황”이라고 말했다.',\n        'SK이노베이션', '연구원', '관계_없음'],\n       ['2011년 7월 비도시치는 AU$320,000의 이적료로 A리그 애들레이드 유나이티드 FC와 3년 계약을 맺으며, 오스트레일리아로 복귀했다.',\n        '애들레이드 유나이티드 FC', 'A리그', '단체:상위_단체'],\n       ['필리포 인차기 신임 감독의 계획에서 제외되었음에도 불구하고, 이탈리아 구단 측이 호비뉴의 주급을 지불하고 \"물고기 군단\"측이 월급으로 R$400,000을 부담하고, 밀란이 R$400,000을 책임질 것으로 발표되었다.',\n        '밀란', '필리포 인차기', '관계_없음'],\n       ['그는 Ludacris(루다크리스)와 폰티액 간에 $1,200만 캠페인 거래를 중개하여 자신의 마케팅 비즈니스를 시작하였고, Pontiac의 광고에는 노래가 나오는 한편, Ludacris의 1시간에 2마일\" 뮤직 비디오에는 Pontiac이 나오게 된다.',\n        '루다크리스', 'Ludacris', '단체:별칭'],\n       ['위원회는 정부의 공식적인 사과와 각 생존자에게 $20,000의 보상을 지불하는 등의 법적인 구제를 권장하였다.',\n        '정부', '생존자', '관계_없음']], dtype=object)"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에만 있는 기호들\n",
    "# R$ 는 replace('R$','금액') 제거하자.\n",
    "# AU$ 는 replace('AU$','금액') 으로 대체하자.\n",
    "# $ 는 replace('$','금액') 으로 대체하자.\n",
    "\n",
    "train.iloc[:,[1,2,5,8]].loc[train[1].apply(lambda x: True if '$' in x else False)].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ` (7개)\n",
    "\n",
    "replace(\"괴물 신인`\",\"괴물 신인\")\n",
    "\n",
    "나머진 replace(\"`\",\"'\") 로 대체하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([['‘2020 대한민국 수공예공모대전’에서 강진군 청자업체인 토우 김유성 대표가 `청자 연리문 금채 다기`를 출품해 금상을 수상했다.',\n        '김유성', '대한민국', '인물:출신성분/국적'],\n       [\"괴물 신인` ITZY(있지)가 JYP엔터테인먼트(이하 JYP) 박진영 대표가 작사, 작곡한 `ICY(아이씨)'로 컴백한다.\",\n        '박진영', 'JYP', '인물:소속단체'],\n       ['2001년 11월 30일 민주노동당 황광우 등이 민주노동당 기관지와 인터넷 홈페이지 등에 `사회당 동지들에게 드리는 7가지 질문\\'이라는 글 등을 싣고 \"조선노동당(조선로동당)은 사회당의 적이냐\"고 묻자 12월 11일 한국사회당은 모든 종류의 테러나 전쟁에 반대하며 \"남한의 노동계급을 이끌고 북한에 쳐들어가 조선노동당을 물리치는 일이 국가간 전쟁의 범주에 속한다\"고 반박하는 한편, \"조선노동당의 사회관이 관철되는 통일에는 단연코 반대한다\" 고 밝힘으로서 시작되었고 사회당은 \\'친북\\'과 구별하기 위해 \\'종북\\'이라는 단어를 사용했다는 주장이있다.',\n        '사회당', '2001년', '관계_없음'],\n       ['2001년 11월 30일 민주노동당 황광우 등이 민주노동당 기관지와 인터넷 홈페이지 등에 `사회당 동지들에게 드리는 7가지 질문\\'이라는 글 등을 싣고 \"조선노동당(조선로동당)은 사회당의 적이냐\"고 묻자 12월 11일 한국사회당은 모든 종류의 테러나 전쟁에 반대하며 \"남한의 노동계급을 이끌고 북한에 쳐들어가 조선노동당을 물리치는 일이 국가간 전쟁의 범주에 속한다\"고 반박하는 한편, \"조선노동당의 사회관이 관철되는 통일에는 단연코 반대한다\" 고 밝힘으로서 시작되었고 사회당은 \\'친북\\'과 구별하기 위해 \\'종북\\'이라는 단어를 사용했다는 주장이있다.',\n        '사회당', '2001년', '관계_없음'],\n       ['88년 노무현, 이해찬 국회의원과 함께 국회 노동위원회에서 활동하며 `노동위 3총사`로 불리기도 했다.',\n        '이해찬', '노무현', '관계_없음'],\n       ['문정원 씨 유튜브 채널 `문정원의 정원`에서 아이, 어른들도 좋아하는 간단 스팸 무스비 레시피를 공개했다.',\n        '문정원', '유튜브', '관계_없음'],\n       ['그들은 《사우스 파크》 시즌 3의 11편인 \"Starvin Marvin, In Space\"의 마지막 부분에서 \"Chewbacca, or I am Chewbacca\"와, 《오르가즈모》(\"Now You\\'re a Man\"), 베이스켓볼(\"Warts on Your Dick\"), 《극장판 사우스 파크》(\"What Would Brian Boitano Do Pt. II\", \"Hell Isn\\'t Good\" 메탈리카의 제임스 헷필드가 노래를 불렀다.) 그리고 《팀 아메리카: 세계 경찰》(\"America, Fuck Yeah, \" \"Everyone Has AIDS, \" \"Only A Woman\" and \"Montage\"). 그들은 또한 몇몇의 `Crack\\'(혹은 `Everybody Loves Crack\\')이라 불리는 라이브 노래와, \"David Kelley, TV Warrior\" 그리고 Primus의 노래중 \"Sgt. Baker\"를 연주했다.',\n        '제임스 헷필드', '메탈리카', '인물:소속단체']], dtype=object)"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에만 있는 기호들\n",
    "# replace(\"괴물 신인`\",\"괴물 신인\")\n",
    "# 웬만하면 replace(\"`\",\"'\") 로 대체하자\n",
    "# AU$ 는 replace('AU$','금액') 으로 대체하자.\n",
    "# $ 는 replace('$','금액') 으로 대체하자.\n",
    "\n",
    "train.iloc[:,[1,2,5,8]].loc[train[1].apply(lambda x: True if '`' in x else False)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minor_concat_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-cdc2e57a4602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mminor_concat_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'minor_concat_data' is not defined"
     ]
    }
   ],
   "source": [
    "minor_concat_data['sentence'].iloc[4].replace(\"'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "46"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bornin_city.apply(lambda x: x['sentence'].index(x['entity_01']),axis=1).argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 외부데이터에서 특수기호 포함하는 행 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\\\n",
      "특수문자 포함\n",
      "<re.Match object; span=(11, 12), match='\\\\'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['?', '>', '\\\\', '+', '*', '※', '^', '…', '=', '『', '}', '`', '@', '{',\n",
    "# '$', '』', '<', '#']\n",
    "import re\n",
    "def exist_punc(word):\n",
    "    reg = re.compile('[?><+*※^…=『』`@$#\\{\\}\\\\\\]')\n",
    "    if reg.search(word):\n",
    "        # print(\"특수문자 포함\")\n",
    "        # print(reg.search(word))\n",
    "        return True\n",
    "    else:\n",
    "        # print(\"특수문자 없음\")\n",
    "        # print(reg.search(word))\n",
    "        return False\n",
    "\n",
    "# bornin_city['sentence'].apply(lambda x: exist_punc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bornin_city.shape)\n",
    "# print(bornin_country.shape)\n",
    "# print(diedin_city.shape)\n",
    "# print(diedin_country.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "관계_없음          4441\n단체:구성원          815\n인물:소속단체         679\n인물:직업/직함        553\n단체:상위_단체        335\n단체:별칭           231\n인물:출신성분/국적      209\n인물:동료           186\n단체:제작           165\n인물:부모님          164\n단체:본사_도시        136\n단체:본사_국가        115\n인물:별칭           103\n인물:배우자           92\n인물:자녀            84\n단체:하위_단체         80\n단체:창립일           67\n인물:기타_친족         58\n인물:제작            56\n인물:형제/자매/남매      52\n단체:창립자           45\n인물:사망_일시         45\n단체:모회사           44\n인물:출생_일시         36\n인물:거주_국가         27\n인물:거주_도시         26\n단체:본사_주(도)       23\n단체:정치/종교성향       18\n단체:해산일           15\n인물:종교            15\n인물:거주_주(도)       12\n단체:주주            11\n인물:용의자           11\n인물:학교             9\n단체:구성원_수          9\n인물:출생_국가          8\n인물:사망_원인          7\n단체:자회사            5\n인물:나이             5\n인물:출생_도시          4\n인물:사망_도시          3\n인물:사망_국가          1\nName: 8, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_vc = train.iloc[:,8].value_counts()\n",
    "from transformers import AutoTokenizer\n",
    "# model_name_from_pretrained = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model_name_from_pretrained = \"xlm-roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_from_pretrained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python377jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}