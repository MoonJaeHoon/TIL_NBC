# 멘토링 세션일지

외부 모델을 이용하여 가져온 피처들을 다시 인풋에 추가할 수 있습니다.

- 유저들을 클러스터링 하기

피처가 많이 생각된다

- 피처가 너무! 중요할 것 같다.!

  > 피처를 5개만 쓰고 트랜스포머를 쓰고 마지막 LSTM했는데 피처를 많이 안썼다. -- 민용

하이퍼 파라미터도 많이 수정해보기

- 로스를 그대로 쓰지 않아도 오케이 입니다.

토론글이 많이 안나오더라구요.

SOTA 보고 Table에 나오는 경향들을 파악하는 게 좋을 수 잇다.

- 점수가 SAKT에서 SAINT로 옮겨갈때 올랐으니 SAINT를 보는게 좋을 것 같다. 한명은 Transformer를 꼭 잡고 있어야겠다.

label인코딩보다 Onehot인코딩을 해보는게 낫겠다.

- 예를 들어 정답수는 커질 수록 좋으니까 label인코딩이 괜찮을수 있지만 다른 것들은 원핫인코딩하는 게 더 좋을 수 있다.

**1등 아니어도 충분히 잘하고 있습니다. 계속 갑시다.**



## 추천 분업 방식

피처들을 계속 발견하거나 테스트를 계속 하는 팀으로 나누고

기존에 있는 피처들을 계속 검증해보는 팀

= 머신러닝(2) | 딥러닝 투 트랙(4)

머신러닝 세부 그룹

- 같은 모델에서 피처를 나눠서 테스트하는 그룹
- 모델을 계속 다양하게 구조화! 하는 그룹

augmentation으로 강해지는 건지, transformer계의 모델류를 선정해서 (다양한 모델을 만드는 것이 중요) 확실히 하는 것이 먼저 해야될 일 같다.

머신러닝모델도 테스트를 많이 해봐야 할 것 같다. LightGBM을 쓰는게 좋을 수 있다. 본인은 딥러닝으로 제출하다가 LightGBM내고 1등했었음(Catboost, LightGBM, XGBoost앙상블 먼저 꼭 해봄)

> 이제 이걸 딥러닝 부류와 비교를 해보면 아 .. 딥러닝이 좋은지 머신러닝이 좋은지 나옵니다

최소한의 피처개수만 가지고 이 모델을 한번 써봤으면 좋겠다. 이번주 수요일까지 GRU , LSTM을 해보시고 누군가 한명은 SAINT를 가지고 시작하면 좋을 것 같다. 그러면 디버깅하는 시간을 버는 거임. Bert , transformer계열 에서 피처바꿔가면서 실험 고고

이번주에 최대한 실험 방향을 정해서 candidate를 정하고 그다음에 3주차에 그 candidate로 실험을 진행을 하면서 마지막에 ensemble로 하면 될 것같다! ensemble은 하드보팅으로!



### 멘토님 경험상 좋았던 것들

마지막에는 knowledgetag를 가지고 낼 수 있는 모든 통계량을 한껏 넣어주는 것.

같은 셋팅에서 피처를 추가 빼기 했을때 영향의 차이를 알 수 있는 것 같다.

독립적으로 모델을 돌려 가져온 (ex) 그래프 모델) 피처를 추가해주는게 도움이 많이 됬다



### 멘토님 질문

- Augmentation을 할 수 있는 task인가요?

(민용) 한사람당 푼 문제수 9~1800개 정도 있는데 max_50을 고려했을 때 마지막 50문제만 가져오는 것이 현재상황이다 _ 그래서 그 전 기록도 이용하면 가능하다.

- 모델별 테스트 실험 소요 시간이 얼마나 걸리나요?

(아라) 머신러닝 5분 정도 걸렸습니다.

(민용) LSTM은 15분 정도 걸렸습니다.
(답변) 굉장히 좋은 .. task네요..!

- 지금 기준없이 fold로 하는 게 노말인거지요?

(민용) stratified 기준을 많이 가져가면서 해봤는데 그때는 피처가 없었다. 현재 있을때 다르니까 다시 굳히기 하면 될거같다.

- 혹시 논문이 있나요?

(민용) 2015 dkt 논문, 트랜스포머, rnn계열을 접목한 모델들이 있긴 하다.[[1\]](https://arxiv.org/pdf/1506.05908.pdf)

- 버트와 같은 모델내의 결과를 가져와서 이용하는 건지 아니면 그냥 임베딩한 결과를 넣어주는 건지 ?

(아라) 임베딩 된 상태를 여러 모델에 넣어주고 있다

- Pseudo Labeling을 해보셨나요??

(멘토님) 포함하라고 굳이 이야기 한게 ㅎㅎ 하라는 것같다



### 우리조 질문

- 점수 분포를 나누는 것은 단계별로 범주를 나눠주는 것continuous feature를 categorical로 바꾸면서 이점을 가져갈 수 있을 것 같다. 이때 원핫인코딩을 해보자

- 맞춘 문제 개수를 continuous로 할까요? categorical로 할까요?
  숫자 자체가 의미를 가지면 continuous를 쓰는게 좋을 것 같다. categorical 및 continous한 변수를 다룰때 피처엔지니어링이 각자 다르다. continuous인 경우에 min, max, count등을 이용할 수 있다.

- 유저의 자체 특징을 추출할 수 있겠는지?
  문제를 총 푼 갯수
  유져 별 정답률
  유저가 어떤 시험지 조합으로 풀었는지
  유저의 특징을 따로 추출해주는 것!

  문제를 푼사람을 임베딩으로 뺄 수 있고
  문제를 임베딩으로 뺄 수 있고
  추천 시스템과 유사하다.

- 피처간에 스케일 문제
  [continuous] 문항에 전체 정답률이 몇 % 인지(0-1).
  [continuous] 총 몇문제를 풀었는가 (9-1800)
  머신러닝에서는 스케일링을 하는게 좋을 것 같다.

- 딥러닝은 임베딩을 거치면서 크게 영향은 없을 듯.

- 서로 다른 피처들이 concat을 해서 들어가게 되는데
  concat말고 있는지?

  multihead attention도 있다.
  concat하는 방법은 많다.

  > 연산을 물어보는건지? 아니면 학습가능하게 가져가려는건지? 향후 실험계획

- 현재 19-20 개 의 피처가 들어간 머신러닝 모델 + 9-10개의 피처가 들어간 딥러닝 모델이다.
  딥러닝에 피처 넣어서 구성 맞춰주시고 돌려보고 비교하면 좋을 것 같다.

- concat 하기전에 continuous를 어떻게 해야되는지?
  continous값을 임베딩을 해도 되기는 합니다.

- concat에 들어가는 각각의 값이 다른 모델에서 학습되어서 나온 결과물일 수 있다.

- multihead attention을 쓸 수 있다. reference가 되는다른 걸 붙였을 때는 괜찮지만. 오래 걸릴수도 있음

- 피처 concat도 다르게 할 수 있다.? 가중치 이용해서



# 피어세션일지

머신러닝 Catboost추가 요청

모델 쪽 아키텍쳐 해보는 그룹, 기존에 피처 검증 하는 그룹 같이 하기로 함.

- positional 임베딩을 쓸 때엔 먼저 임베딩을 한건가?

huggingface가 아니라 modelin 버트에서 가져오는 것 같은데 예전에는 positional인코딩한 걸 썼었다. 내부에서 positional encoding을 했었다.

기존의 베이스라인 모델을 개선하는 팀이랑 모델 구성해보는 팀으로 나눠도 될 것 같다. 피처는 그대로 같이 해보면 될 것 같다. 논문은 읽어오고 같이 이해하고 그렇게 하면 될것 같다.

SAINT를 같이 읽어오기로 하자 _ 민용 아라 정현

피처를 좀 더 분석해보겠습니다 _ 정현

DKT논문 읽기 _ 정현 민용

클러스터링 같이 해볼사람! _ 민용 유라

유의미한 피처를 이용해서 클러스터링을 하는게 빡세겠군 _ 재훈

- OnehotEncoder 의미

labelEncoder를 쓰면 가중치가 늘어난다고 생각하는 경우가 될 수 있어서 1-1500 으로 들어가는 것보다 onehot인코딩으로 넣어보라고 한것 같다.

weight를 곱해주니까 임베딩할때 영향이 클거같음!

- 팀 과업 목록

피처 다 추가해서 각자의 모델에서 비교해주는 것 +논문 읽는 것까지 ! +클러스터링! +원핫인코딩해서 해보기

- 매일 할일 추가요!

나만의 목표를 디스커션에 올라온 일지에 댓글로 남기기 나만의 목표니까 개인적으로 구체적이게 쓰기 (이 함수를 이해한다 ! 처럼)



# 오늘 계획

1.
아라와 민용이의 피쳐까지 모두 추가하여
lgbm을 돌린다음 제출해보고, 점수 보고하겠습니다


2.
Categorical Variable에 대해서 One-hot Encoding 적용해서 기존의 코드로 실험해보기


3.
기존에 특정기준으로 나누어서 Valid Set을 찾은 결과가 매우 좋아보였는데
변수추가, 모델 아키텍쳐 변화 등에 결과가 매우 상이해져버렸습니다
따라서, Valid Set을 나누는 기준을 다시 정하는 실험을 하겠습니다

3-1) 현재 특정 기준의 row만 골라서 Valid 사용중 => 해당 기준을 변화해보기

3-2) 기준 없이 Random하게 적용해보기

3-3) Stratified KFold 적용해보기