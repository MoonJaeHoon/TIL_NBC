> 스스로 시도& 구현한 부분
>
> - DeepLearning Fold별 정보 저장
>   - Dictionary 형태로 만든 후, json파일 & CSV파일 저장
>   
>   <img src="%EC%B5%9C%EC%A2%85%ED%9A%8C%EA%B3%A0%EB%A1%9D_%EB%9E%A9%EC%97%85%EB%A6%AC%ED%8F%AC%ED%8A%B8.assets/image-20210616160506264.png" alt="image-20210616160506264" style="zoom:50%;" />
>   
> - Riid Dataset Processing for Pre-training
>   - 해당 데이터는 DKT 분야 Competition에서 유명한 DataSet
>     - 우리 대회 Task에 Pre-training한 모델을 가져와서 Fine-tuning을 하는 방법론을 적용해볼 수 있을까 하는 관점에서 유의깊게 보게 된 DataSet이다.
>     - 간단한 EDA 결과, 전체 정답률의 분포가 약 65:35 (정답:오답)으로 우리의 데이터셋과 그 분포가 매우 비슷하였다.
>     
>     ![image-20210616154602924](%EC%B5%9C%EC%A2%85%ED%9A%8C%EA%B3%A0%EB%A1%9D_%EB%9E%A9%EC%97%85%EB%A6%AC%ED%8F%AC%ED%8A%B8.assets/image-20210616154602924.png)
>     
>     - 해당 데이터가 가지고 있는 변수들 중 유사한 변수가 많았다. (Tag, Timestamp, user_id, content_id, content_type_id)
>     
>   - Pre-train 후 다양한 Deep Learning의 BackBone으로서 Fine-tuning을 적용해봄.
>   
>   - PreProcessing kernel
>   
>   - 현재 Task의 Dataset과 변수의 의미 측면에서 비슷한 형태로 구축
>   
>   - Pre-train 결과, 성능 측면에 있어 도움이 되지 않았음 (LSTM, LSTM-ATTN, GRU-ATTN, ...)
>     
>     - Valid 성능 (LSTM : 0.8081 -> 0.8085), (GRU-ATTN : 0.8180 -> 0.8183)
>     - 현재 대회에서의 Dataset과는 특성 자체가 달랐음 : 캐글의 Riid Dataset은 TOEIC 과련 Dataset, 이 중에는 데이터도 Lecture Data가 포함되었다는 점, 그 의미가 비슷해보이는 변수들도 존재했지만 결국 그 의미가 명백히 같지 않았음 (ex. Tag라는 변수는 KnowledgeTag와 비슷해보이지만 그 의미가 달랐음.)
>   
> - Feature Engineering
>   - 단순 반복문을 활용한 코드들을 Pandas의 메소드를 사용하여 효율성 향상
>   - `groupby`, `join`, `merge`, `etc`..
>   
> - Feature Selection
>   - Permutation Importance
>   - Feature Importance & Shap
>
> - HoldOut Set 구축
>   - LB의 DataSet과 최대한 비슷한 분포를 가지는 HoldOut Set을 구축하려 했음
>   - 이 때 HoldOut Set은 Train과 HyperParameter Tuning에 있어서 아예 사용되지 않는 Data를 뜻함.
>   
>   <img src="https://user-images.githubusercontent.com/63627253/120486724-46a94d80-c3f0-11eb-8ece-485545de70ac.JPG" alt="슬라이드1" style="zoom: 50%;" />
>   
>   <img src="https://user-images.githubusercontent.com/63627253/120491140-f502c200-c3f3-11eb-87b2-11ddb1d5b350.jpg" alt="2" style="zoom:50%;" />
>   
>   <img src="https://user-images.githubusercontent.com/63627253/120486743-4a3cd480-c3f0-11eb-819f-c44736e0bca4.JPG" alt="슬라이드3" style="zoom:50%;" />
>   
> - Dealing with Imablanced Data
>   - SMOTE
>   
>   
>   
> - Customized CV
>   - User의 마지막 row만을 Valid Set으로 사용하기 위한 Last KFold
>   
> - Customizing AUTOML library (Pycaret, Optuna)
>   - Optuna with Medain Pruning & Optuna objective 새로 정의
>   - Pycaret 라이브러리 내부 수정, Cross-Validation Log, Plot, Model Saving을 위한 함수 정의
>   
> - ML models
>   - LightGBM
>   - CatBoost
>   - XGBoost
>   - GBM
>   - NGBoost
>   - LDA (Linear Discriminant Analysis)
>   
> - Output 파일 비교
>
>   - Submission 전 Output의 Confidence 파악
>
>   ![image-20210616155153320](%EC%B5%9C%EC%A2%85%ED%9A%8C%EA%B3%A0%EB%A1%9D_%EB%9E%A9%EC%97%85%EB%A6%AC%ED%8F%AC%ED%8A%B8.assets/image-20210616155153320.png)







## 팀에서 시도해본 것들





## 다른 조 분들

1. Valid를 마지막 행으로 했을 때, 일부를 train하긴 해야함

2. 다중공선성을 고려한 변수선택

3. 이동평균을 이용한 변수생성

4. 0과 1 중에 랜덤하게 정답을 새로 부여하였음 (test의 마지막 row는 정답을 모르니까 Feature Engineering 시에 문제가 있었음, valid의 마지막 row에도 test와 같은 환경을 부여해야 하므로 새로 정답을 랜덤하게 부여하고 Feature Engineering)
