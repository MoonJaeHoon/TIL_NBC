> 스스로 시도해본 것들
>
> - DeepLearning Fold별 정보 저장
>   - Dictionary 형태로 만든 후, json파일 저장
> - Riid Dataset Processing for Pre-training
>   - 해당 데이터는 DKT 분야 Competition에서 유명한 DataSet
>     - 우리 대회 Task에 Pre-training한 모델을 가져와서 Fine-tuning을 하는 방법론을 적용해볼 수 있을까 하는 관점에서 유의깊게 보게 된 DataSet이다.
>     - 간단한 EDA 결과, 전체 정답률의 분포가 약 65:35 (정답:오답)으로 우리의 데이터셋과 그 분포가 매우 비슷하였다.
>     - 
>   - Deep Learning Model
>   - PreProcessing을 위해 팀원들과 많은 소통을 거쳤음
>   - 최대한 현재 Task의 Dataset과 비슷한 형태로 구축하기 위해 노력
>   - 아쉬운 부분 : 성능 측면에 있어 매우 미미한 향상
>     - 현재 대회에서의 Dataset과는 특성 자체가 달랐음 : 캐글의 Riid Dataset은 TOEIC 시험 Dataset이기도 하고, 이 중에는 데이터도 Lecture Data가 포함되었다는 점, 그 의미가 비슷해보이는 변수들도 존재했지만 명백히 같지 않았음 (ex. Tag라는 변수는 KnowledgeTag와 비슷해보이지만 그 의미가 달랐음.)
> - Feature Engineering
>   - 단순 반복문을 활용한 코드들을 Pandas의 메소드를 사용하여 효율성 향상
>   - `groupby`, `join`, `merge`, `etc`..
> - Feature Selection
>   - Permutation Importance
>   - Feature Importance & Shap
>
> - HoldOut Set 구축
>   - LB의 DataSet과 최대한 비슷한 분포를 가지는 HoldOut Set을 구축하려 했음
>   - 이 때 HoldOut Set은 Train과 HyperParameter Tuning에 있어서 아예 사용되지 않는 Data를 뜻함.
> - Dealing with Imablanced Data
>   - SMOTE
> - Customized CV
>   - User의 마지막 row만을 Valid Set으로 사용하기 위한 Last KFold
> - Customizing AUTOML library (Pycaret, Optuna)
>   - Optuna with Medain Pruning & Optuna objective 새로 정의
>   - Pycaret 라이브러리 내부 수정, Cross-Validation Log, Plot, Model Saving을 위한 함수 정의
> - ML models
>   - LightGBM
>   - CatBoost
>   - XGBoost
>   - GBM
>   - NGBoost
>   - LDA (Linear Discriminant Analysis)

