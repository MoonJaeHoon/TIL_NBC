# 0304피어세션정리(인터뷰연습)

<2번과 3번 질문 해결되지 않았음>



1. standard scaler와 minmax scaler의 장단점, 단점의 해결방법

- StandardScaler 와 MinMaxScaler는 이상치에 민감하게 scaling되어 분포를 그대로 유지하지 못하게 된다.
- RobustScaler : 평균 대신 중앙값을 씀으로써 보다 이상치에 영향을 받지 않고, 분포형태를 유지하게끔 scaling을 할 수 있게 된다. (표준편차를 구하는 공식에도 평균 대신 중앙값을 사용한다.)

> 참고 : https://mkjjo.github.io/python/2019/01/10/scaler.html





2. GAN이 Seq2Seq모델에 적용가능한지

- Seq2seq에 GAN을 적용해야 한다면, Generator 모델의 결과는 이산 확률 분포(seq)이기 때문에 적용할 수 없다.

- Electra모델은 GAN과 비슷한 형태를 활용하는데 성공했다?



※ GAN을 seq2seq에 적용할 수 없는 이유 정리

> GAN은 Continuous Data를 생성해내는 것에 대해서는 잘 작동하였다.
>
> 하지만 만약 GAN을 seq2seq모델에 적용한다면, Generator를 통해 생성되어야 하는 sequence의 형태가 discrete여야 할 것이다.
>
> 
>
> 다시 말하자면, 이는 `discrete를 생성하는 Generator -> Discrminator`까지의 과정에서 가중치 업데이트를 역전파법을 사용해서 수행해야 한다는 것이다.
>
> 이 부분을 세부적으로 살펴보면 Generator가 생성할 수 있는 값은 softmax를 통한 확률을 나타내는 연속적인 값에 불과할 것이고, `공간상에서 이 값과 그나마 유사한 seq를 찾아` generate를 수행하게 될 것이다.
>
> 하지만 밑줄친 부분은 역전파법을 통해 딥러닝 모델이 학습할 수가 없는 부분이다.
>
> 따라서 GAN을 seq2seq 모델에 적용할 수가 없다.



※ 만약 위의 정리된 내용(GAN을 seq2seq에 적용할 수 없는 이유)이 맞다면, 이에 이어지는 질문입니다.

> 사실 `공간상에서 이 값과 그나마 유사한 seq를 찾는 과정`을 생각하지 않고, Generator 과정에서 나온 softmax 값까지만을 이용해서 Discriminator가 판별하게끔 모델의 구조를 짠다면 충분히 GAN을 seq2seq에 적용할 수 있지 않을까요?



<u>참고1 : https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-11/01-intro</u>  (GAN을 seq2seq에 적용하지 못한다.)



<u>참고2 : https://settlelib.tistory.com/33 (GAN, DCGAN, cGAN 등의 개념에대한 설명, GAN의 한계점)</u>



<u>참고3 : https://ai-information.blogspot.com/2019/03/nl-02<u>8-seqgan-sequence-generative.html (SeqGAN은 어떻게 구성되어있는가?)</u>



<u>참고4 : https://youtu.be/BXODIP3QjJI (SeqGAN 유튜브 설명)</u>



3. Multi head attention에서 matmul을 사용하는데 고차원에선 이러한 곱연산이 어떻게 이루어지는가? (예를들어 3, 4차원 정도의 고차원일 경우 matmul연산이 어떻게 이루어지는가?)

- A는 7x5x4x3 차원, B는 7x5x3x4 차원일 때 결과는 7x5x4x4의 shape이 나온다.
- 이는 뒤의 두 dimension이 나타내는 행렬의 차원의 곱이 성립하고, 앞의 shape (위의 경우는 x5, 7x5)이 모두 같다면 곱 연산이 가능하다.

> 참고1 : https://ebbnflow.tistory.com/159



<조교님, np.dot 과 np.matmul()의 연산과정에서 차이가 무엇인지 설명해주세요..>

- np.dot 함수는 dot product로서 내적연산을 한다고 알고 있었는데 고차원에서의 np.dot연산의 결과는 다음 코드를 보면 차원이 추가되어버리는 것(?) 같아서 이해가 잘 되질 않습니다..

```
>>> import numpy as np
>>> A = np.arange(2*3*4).reshape((2,3,4))
>>> B = np.arange(2*3*4).reshape((2,4,3))
>>> np.dot(A,B).shape
(2, 3, 2, 3)

```





4. CNN에서 층을 많이 쓰면 좋다고 알려져있는데 왜 막상 많이 쌓으면 안좋은가, 이를 어떻게 해결했는가?

- 층이 많아지면 파라미터가 계속해서 곱해지면서 작아지니까? 앞단의 정보가 희석이 되니까
- 이를 해결하기 위해 만든 것이 ResNet 모델이다. 이것은 구조상 아웃풋에 x를 더해줌으로써 CNN층을 더욱 깊게 쌓더라도 전층의 정보를 유지할 수 있게 하였다.
- 1X1 convolution layer를 쓰는 이유 : 원래의 형상을 유지할 수 있어 성능은 유지하면서도 파라미터 수를 줄일 수가 있다.



5. LSTM과 GRU의 차이는?

- Cell state가 없다,  GRU는 게이트가 2개이고, LSTM은 3개이다. (LSTM에 있는 출력 게이트가 없다)



6. Word Embedding이란?

- 컴퓨터가 텍스트를 인식할 수 없으니까 수치화 시켜주는 것
- 예시로 tf-idf, Word2vec과 Glove 등이 있다.

6-1. One-hot Encoding보다 Word Embedding이 좋은 이유

- 단어간 연관성을 반영할 수 있다
- Embedding 차원만큼만 학습하면 되므로 연산상에 이득이 있다.

6-2. word2vec 을 딥러닝 모델이라고 볼 수 있나요??

- 은닉층이 하나밖에 없고 활성화함수가 없기 때문에 딥러닝이 아니다



7. Bias-Variance Trade off

- Bias는 train시 y와 predict 값의 차이를 의미한다.
- 이 Bias를 줄이는 것으로 너무 과대적합을 하게 되면 Variance가 높게 되는 경우가 생기는데 이것이 Bias-Variance Trade off이다.

> 예외로 생각해볼만한 것 - 최근에 Train시 최대한 과대적합을 시키는 것이 Test시 성능이 오히려 더 올라가는 것을 실험에서 보인 적이 있다.



=================================================

Overfitting이 무조건 좋지 않은 걸까?에 대한 의문을 가져야 한다고 말씀드렸었는데, 이와 관련된 작년 남세동님의 발표영상입니다 (출처 : MODUCON)

> 다음 영상의 31분 18초 정도에 제가 언급했던 그림이 나옵니다..!
>
> (이외에도 우리가 의문을 가져왔을 법한 부분들에 대해 언급이 있습니다. 내용이 궁금하신 분은 영상 정주행 해보시는 것도 재밌어요)
>
> 참고 : https://www.youtube.com/watch?v=YjfryJhb9Zg&t=2s

